<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Running the analyses &mdash; autoregressive-bbh-inference  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Figure generation" href="making-figures.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> autoregressive-bbh-inference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="making-figures.html">Figure generation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Running the analyses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#autoregressive-mass-and-mass-ratio-inference">Autoregressive mass and mass ratio inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="#redshift-evolution-of-the-merger-rate">Redshift evolution of the merger rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="#component-spin-magnitudes-and-tilts">Component spin magnitudes and tilts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#effective-inspiral-and-precessing-spins">Effective inspiral and precessing spins</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">autoregressive-bbh-inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Running the analyses</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/running-the-analyses.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="running-the-analyses">
<h1>Running the analyses<a class="headerlink" href="#running-the-analyses" title="Permalink to this heading"></a></h1>
<p>Here, we detail how to rerun our code to recreate the data stored at <a class="reference external" href="https://zenodo.org/record/7600140">https://zenodo.org/record/7600140</a>.</p>
<section id="autoregressive-mass-and-mass-ratio-inference">
<h2>Autoregressive mass and mass ratio inference<a class="headerlink" href="#autoregressive-mass-and-mass-ratio-inference" title="Permalink to this heading"></a></h2>
<p>To rerun our autoregressive inference on the primary mass and mass ratio distribution of BBHs, do the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda<span class="w"> </span>activate<span class="w"> </span>gwtc3-spin-studes
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>code/
$<span class="w"> </span>python<span class="w"> </span>run_ar_lnm1_q.py
</pre></div>
</div>
<p>This script will launch <cite>numpyro</cite>, using the likelihood model <a class="reference internal" href="autoregressive_mass_models.html#autoregressive_mass_models.ar_lnm1_q" title="autoregressive_mass_models.ar_lnm1_q"><code class="xref py py-meth docutils literal notranslate"><span class="pre">autoregressive_mass_models.ar_lnm1_q()</span></code></a>.
This may take several hours to complete.
The output will be two files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>final-ar_lnm1_q.cdf
final-ar_lnm1_q_data.npy
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Before running, open <cite>run_ar_lnm1_q.py</cite> and change the output filepaths to suitable locations!
These output files will, by default, be written to a directory that likely does not exist on your system.</p>
<p>Also, be aware that <cite>file-ar_lnm1_q.cdf</cite> is <em>large</em>, running a little over 20 GB.</p>
</div>
<p>The file <code class="code docutils literal notranslate"><span class="pre">final-ar_lnm1_q_data.npy</span></code> contains arrays holding all the mass and mass ratios in our dataset (including posterior samples and injections);
these are the values over which our AR processes are defined.
This file also contains information used to sort or reverse sort these values, used inside the likelihood function.
The file <code class="code docutils literal notranslate"><span class="pre">final-ar_lnm1_q.cdf</span></code>, in turn, contains the full inference output, including posterior samples and inference diagnostics.</p>
<p>Finally, we distill the full inference output into the restricted set of data that will be used for downstream analyses and figure generation.
This is done via</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>../data/
$<span class="w"> </span>python<span class="w"> </span>process_lnm1_q.py
</pre></div>
</div>
<p>This script will load the two files above and create a single (much smaller!) output file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ar_lnm1_q_summary.hdf
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A notebook that demonstrates how to load in, inspect, and manipulate this output file can be found <a class="reference external" href="https://github.com/tcallister/autoregressive-bbh-inference/blob/main/data/inspect_ar_lnm1_q_results.ipynb">here</a></p>
</div>
</section>
<section id="redshift-evolution-of-the-merger-rate">
<h2>Redshift evolution of the merger rate<a class="headerlink" href="#redshift-evolution-of-the-merger-rate" title="Permalink to this heading"></a></h2>
<p>To rerun our autoregressive inference on the BBH merger rate evolution with redshift, do the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda<span class="w"> </span>activate<span class="w"> </span>gwtc3-spin-studes
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>code/
$<span class="w"> </span>python<span class="w"> </span>run_ar_z.py
</pre></div>
</div>
<p>This script will launch <cite>numpyro</cite>, using the likelihood model <a class="reference internal" href="autoregressive_redshift_models.html#autoregressive_redshift_models.ar_mergerRate" title="autoregressive_redshift_models.ar_mergerRate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">autoregressive_redshift_models.ar_mergerRate()</span></code></a>.
This may take several hours to complete.
The output will be two files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>final-ar_z.cdf
final-ar_z_data.npy
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Before running, open <cite>run_ar_z.py</cite> and change the output filepaths to suitable locations!
These output files will, by default, be written to a directory that likely does not exist on your system.</p>
<p>Also, be aware that <cite>file-ar_z.cdf</cite> is <em>large</em>, running at about 15 GB.</p>
</div>
<p>The file <code class="code docutils literal notranslate"><span class="pre">final-ar_z_data.npy</span></code> contains arrays holding all the redshifts in our dataset (including posterior samples and injections);
these are the values over which our AR process is defined.
This file also contains information used to sort or reverse sort these values, used inside the likelihood function.
The file <code class="code docutils literal notranslate"><span class="pre">final-ar_z.cdf</span></code>, in turn, contains the full inference output, including posterior samples and inference diagnostics.</p>
<p>Finally, we distill the full inference output into the restricted set of data that will be used for downstream analyses and figure generation.
This is done via</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>../data/
$<span class="w"> </span>python<span class="w"> </span>process_z.py
</pre></div>
</div>
<p>This script will load the two files above and create a single (much smaller!) output file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ar_z_summary.hdf
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A notebook that demonstrates how to load in, inspect, and manipulate this output file can be found <a class="reference external" href="https://github.com/tcallister/autoregressive-bbh-inference/blob/main/data/inspect_ar_z_results.ipynb">here</a></p>
</div>
</section>
<section id="component-spin-magnitudes-and-tilts">
<h2>Component spin magnitudes and tilts<a class="headerlink" href="#component-spin-magnitudes-and-tilts" title="Permalink to this heading"></a></h2>
<p>To rerun our autoregressive inference on the BBH component spin distribution, do the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda<span class="w"> </span>activate<span class="w"> </span>gwtc3-spin-studes
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>code/
$<span class="w"> </span>python<span class="w"> </span>run_ar_chi_cost.py
</pre></div>
</div>
<p>This script will launch <cite>numpyro</cite>, using the likelihood model <a class="reference internal" href="autoregressive_spin_models.html#autoregressive_spin_models.ar_spinMagTilt" title="autoregressive_spin_models.ar_spinMagTilt"><code class="xref py py-meth docutils literal notranslate"><span class="pre">autoregressive_spin_models.ar_spinMagTilt()</span></code></a>.
This may take several hours to complete.
The output will be two files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>final-ar_chi_cost.cdf
final-ar_chi_cost_data.npy
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Before running, open <cite>run_ar_chi_cost.py</cite> and change the output filepaths to suitable locations!
These output files will, by default, be written to a directory that likely does not exist on your system.</p>
<p>Also, be aware that <cite>file-ar_chi_cost.cdf</cite> is <em>large</em>, running a little over 40 GB.</p>
</div>
<p>The file <code class="code docutils literal notranslate"><span class="pre">final-ar_chi_cost_data.npy</span></code> contains arrays holding all the spin magnitudes and cosine tilts in our dataset (including posterior samples and injections);
these are the values over which our AR processes are defined.
This file also contains information used to sort or reverse sort these values, used inside the likelihood function.
The file <code class="code docutils literal notranslate"><span class="pre">final-ar_chi_cost.cdf</span></code>, in turn, contains the full inference output, including posterior samples and inference diagnostics.</p>
<p>Finally, we distill the full inference output into the restricted set of data that will be used for downstream analyses and figure generation.
This is done via</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>../data/
$<span class="w"> </span>python<span class="w"> </span>process_chi_cost.py
</pre></div>
</div>
<p>This script will load the two files above and create a single (much smaller!) output file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ar_chi_cost_summary.hdf
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A notebook that demonstrates how to load in, inspect, and manipulate this output file can be found <a class="reference external" href="https://github.com/tcallister/autoregressive-bbh-inference/blob/main/data/inspect_ar_chi_cost_results.ipynb">here</a></p>
</div>
</section>
<section id="effective-inspiral-and-precessing-spins">
<h2>Effective inspiral and precessing spins<a class="headerlink" href="#effective-inspiral-and-precessing-spins" title="Permalink to this heading"></a></h2>
<p>To rerun our autoregressive inference on the BBH effective spin distribution, do the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>conda<span class="w"> </span>activate<span class="w"> </span>gwtc3-spin-studes
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>code/
$<span class="w"> </span>python<span class="w"> </span>run_ar_Xeff_Xp.py
</pre></div>
</div>
<p>This script will launch <cite>numpyro</cite>, using the likelihood model <a class="reference internal" href="autoregressive_spin_models.html#autoregressive_spin_models.ar_Xeff_Xp" title="autoregressive_spin_models.ar_Xeff_Xp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">autoregressive_spin_models.ar_Xeff_Xp()</span></code></a>.
This may take several hours to complete.
The output will be two files:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>final-ar_Xeff_Xp.cdf
final-ar_Xeff_Xp_data.npy
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Before running, open <cite>run_ar_Xeff_Xp.py</cite> and change the output filepaths to suitable locations!
These output files will, by default, be written to a directory that likely does not exist on your system.</p>
<p>Also, be aware that <cite>file-ar_Xeff_Xp.cdf</cite> is <em>large</em>, running a little over 25 GB.</p>
</div>
<p>The file <code class="code docutils literal notranslate"><span class="pre">final-ar_Xeff_Xp_data.npy</span></code> contains arrays holding all the effective inspiral and precessing spins in our dataset (including posterior samples and injections);
these are the values over which our AR processes are defined.
This file also contains information used to sort or reverse sort these values, used inside the likelihood function.
The file <code class="code docutils literal notranslate"><span class="pre">final-ar_Xeff_Xp.cdf</span></code>, in turn, contains the full inference output, including posterior samples and inference diagnostics.</p>
<p>Finally, we distill the full inference output into the restricted set of data that will be used for downstream analyses and figure generation.
This is done via</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>../data/
$<span class="w"> </span>python<span class="w"> </span>process_Xeff_Xp.py
</pre></div>
</div>
<p>This script will load the two files above and create a single (much smaller!) output file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ar_Xeff_Xp_summary.hdf
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A notebook that demonstrates how to load in, inspect, and manipulate this output file can be found <a class="reference external" href="https://github.com/tcallister/autoregressive-bbh-inference/blob/main/data/inspect_ar_Xeff_Xp_results.ipynb">here</a></p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="making-figures.html" class="btn btn-neutral float-left" title="Figure generation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Tom Callister &amp; Will Farr.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>